glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price+room_type, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price +
room_type +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price +
host +
room_type +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price +
host_id +
room_type +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
#DECISION TREE
#(only using selected predictors for decision tree and random forest which are useful)
dec_fit <- train_set %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))
#DECISION TREE
#(only using selected predictors for decision tree and random forest which are useful)
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ host_id +
room_type +
price +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 10) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 10) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ host_id +
room_type +
price +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 10) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 10) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
tmp <- train_set %>%
mutate(price_round = round(price, digits=-1)) %>%
group_by(price_round) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp <- train_set %>%
mutate(price_round = round(price, digits=-1)) %>%
group_by(price_round) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$price_round), max(tmp$price_round))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*price_round))
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price")
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
#ANALYSIS FOR LM
#filter rounded price groupings with n()>=5
glm_pre <- train_set %>%
mutate(price_round = round(price, digits=-1)) %>%
group_by(price_round) %>%
mutate(n=n()) %>%
filter(n>=5) %>%
ungroup() %>%
select(-price_round, -n)
#Proportion manhattan listings per price in tens
glm_pre %>%
mutate(price_round = round(price, digits=-1)) %>%
group_by(price_round) %>%
summarize(n=n(), proportion_manhattan=mean(neighbourhood_group=="Manhattan")) %>%
mutate(proportion_manhattan = round(proportion_manhattan, digits=2)) %>%
ggplot(aes(price_round, proportion_manhattan)) +
geom_point() +
geom_text(aes(label=proportion_manhattan))
#Proportion room type 'Apartment' per price
glm_pre %>%
mutate(price_round = round(price, digits=-1)) %>%
group_by(price_round) %>%
summarize(n=n(), mrt=mean(room_type=="Entire home/apt")) %>%
mutate(mrt = round(mrt, digits=2)) %>%
ggplot(aes(price_round, mrt)) +
geom_point() +
geom_text(aes(label=mrt))
#GLM TUTORIAL (why different accuracies between my lm(cat) and glm?)
#generalized lm (for one or several predictors)
fit_log <- train_set %>%
glm(manhattan=="manhattan" ~ price, data=., family = "binomial")
#or
#glm_fit <- train_set %>%
#mutate(y=as.numeric(manhattan=="manhattan")) %>%
#glm(y ~ price, data=., family = "binomial")
p_hat_log <- predict(fit_log, newdata = test_set, type = "response")
y_hat_log <- factor(ifelse(p_hat_log > 0.50, "manhattan", "not_manhattan"))
confusionMatrix(data=y_hat_log, reference=test_set$manhattan)$overall["Accuracy"]
#GLM TUTORIAL (why different accuracies between my lm(cat) and glm?)
#generalized lm (for one or several predictors)
fit_log <- glm_pre %>%
glm(manhattan=="manhattan" ~ price, data=., family = "binomial")
#or
#glm_fit <- train_set %>%
#mutate(y=as.numeric(manhattan=="manhattan")) %>%
#glm(y ~ price, data=., family = "binomial")
p_hat_log <- predict(fit_log, newdata = test_set, type = "response")
y_hat_log <- factor(ifelse(p_hat_log > 0.50, "manhattan", "not_manhattan"))
confusionMatrix(data=y_hat_log, reference=test_set$manhattan)$overall["Accuracy"]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
#logistic regression model (listing in manhattan with several predictors)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ host_id +
room_type +
price +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
#logistic regression model (listing in manhattan with several predictors)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~
price
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
#logistic regression model (listing in manhattan with price as predictor)
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)#$overall[["Accuracy"]]
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)$overall[["Accuracy"]]
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ host_id +
room_type +
price +
minimum_nights +
number_of_reviews +
reviews_per_month +
calculated_host_listings_count +
availability_365
, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
glm_fit <- glm_pre %>%
mutate(y = as.numeric(manhattan == "manhattan")) %>%
glm(y ~ price, data=., family = "binomial")
p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")
y_hat_logit <- ifelse(p_hat_logit > 0.5, "manhattan", "not_manhattan") %>% factor
confusionMatrix(y_hat_logit, test_set$manhattan)$overall[["Accuracy"]]
tmp <- train_set %>%
mutate(x = round(price, digits=-1)) %>%
group_by(x) %>%
filter(n() >= 5) %>%
summarize(prop = mean(manhattan == "manhattan"))
logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))
tmp %>%
ggplot(aes(x, prop)) +
geom_point() +
geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2) +
xlab("price") +
ylab("proportion")
#10-FOLD CROSS VALIDATION
control <- trainControl(method = "cv", number = 10, p = .9)
#KNN train needs long time
m_knn <- train_set %>%
train(manhattan~host_id +
room_type +
price +
minimum_nights +
number_of_reviews +
calculated_host_listings_count +
availability_365,
method="knn",
data=.,
tuneGrid = data.frame(k = seq(5))
#trControl=control
)
train_set
#DECISION TREE
#(only using selected predictors for decision tree and random forest which are useful)
dec_fit <- train_set %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))
#DECISION TREE
#(only using selected predictors for decision tree and random forest which are useful)
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))
#DECISION TREE
#(only using selected predictors for decision tree and random forest which are useful)
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
train_set %>%
ggplot(aes(room_type, price, col=manhattan, size=calculated_host_listings_count)) +
geom_point(alpha=0.2)+
scale_y_continuous(trans="log2")
glm_pre %>%
ggplot(aes(room_type, price, col=manhattan, size=calculated_host_listings_count)) +
geom_point(alpha=0.2)+
scale_y_continuous(trans="log2")
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))
confusionMatrix(table(fit_pred, test_set$manhattan))$overall[["Accuracy"]]
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))$overall[["Accuracy"]]
confusionMatrix(table(fit_pred, test_set$manhattan))
?confusionMatrix
dec_fit <- glm_pre %>%
select(host_id,
room_type,
price,
minimum_nights,
number_of_reviews,
calculated_host_listings_count,
availability_365,
manhattan
) %>%
rpart(manhattan ~ ., data=., model=TRUE)
fit_pred <- predict(dec_fit, test_set, type="class")
confusionMatrix(table(fit_pred, test_set$manhattan))$overall[["Accuracy"]]
rpart.plot(dec_fit)
rpart.plot(dec_fit)
rpart.plot(dec_fit)
